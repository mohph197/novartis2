{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2efa971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759a3dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = pd.read_csv('data/train/df_volume_train.csv')\n",
    "gxs = pd.read_csv('data/train/df_generics_train.csv')\n",
    "info = pd.read_csv('data/train/df_medicine_info_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ec355",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = vol.merge(\n",
    "    gxs,\n",
    "    on=['country', 'brand_name', 'months_postgx'],\n",
    "    how='left',\n",
    "    validate='one_to_one'\n",
    ")\n",
    "df = df.merge(\n",
    "    info,\n",
    "    on=['country', 'brand_name'],\n",
    "    how='left',\n",
    "    validate='many_to_one'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41eeec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Avgj\n",
    "avgj = (\n",
    "    df[df[\"months_postgx\"].between(-12, -1)]\n",
    "    .groupby([\"country\", \"brand_name\"])[\"volume\"]\n",
    "    .mean()\n",
    "    .rename(\"Avgj\")\n",
    ")\n",
    "\n",
    "df = df.merge(avgj, on=[\"country\", \"brand_name\"], how=\"left\", validate=\"many_to_one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2598ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target_norm\"] = df[\"volume\"] / df[\"Avgj\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97047b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = df[df[\"months_postgx\"] < 0]\n",
    "\n",
    "pre_stats = pre.groupby([\"country\", \"brand_name\"])[\"target_norm\"].agg(\n",
    "    pre_mean=\"mean\",\n",
    "    pre_std=\"std\",\n",
    "    pre_min=\"min\",\n",
    "    pre_max=\"max\",\n",
    "    pre_trend=lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x)>1 else 0\n",
    ")\n",
    "\n",
    "df = df.merge(pre_stats, on=[\"country\", \"brand_name\"], how=\"left\", validate=\"many_to_one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f01159",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = {\n",
    "    \"t1\": (-24, -22),\n",
    "    \"t2\": (-21, -19),\n",
    "    \"t3\": (-18, -16),\n",
    "    \"t4\": (-15, -13),\n",
    "    \"t5\": (-12, -10),\n",
    "    \"t6\": (-9, -7),\n",
    "    \"t7\": (-6, -4),\n",
    "    \"t8\": (-3, -1),\n",
    "}\n",
    "\n",
    "trimester_frames = []\n",
    "\n",
    "for name, (start, end) in windows.items():\n",
    "    tmp = (\n",
    "        df[df[\"months_postgx\"].between(start, end)]\n",
    "        .groupby([\"country\", \"brand_name\"])[\"target_norm\"]\n",
    "        .agg(\n",
    "            **{\n",
    "                f\"{name}_mean\": \"mean\",\n",
    "                f\"{name}_std\": \"std\",\n",
    "                f\"{name}_min\": \"min\",\n",
    "                f\"{name}_max\": \"max\",\n",
    "                f\"{name}_trend\": lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x)>1 else 0,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    trimester_frames.append(tmp)\n",
    "\n",
    "# Combine trimester stats\n",
    "trimester_stats = pd.concat(trimester_frames, axis=1)\n",
    "\n",
    "# Merge\n",
    "df = df.merge(trimester_stats, on=[\"country\", \"brand_name\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c768d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['months_postgx_sin'] = np.sin(df['months_postgx']* (2.*np.pi/12))\n",
    "df['months_postgx_cos'] = np.cos(df['months_postgx']* (2.*np.pi/12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d08b96f",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4eb1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique pairs\n",
    "pairs = df[[\"country\", \"brand_name\"]].drop_duplicates()\n",
    "\n",
    "train_pairs, eval_pairs = train_test_split(\n",
    "    pairs,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "eval_pairs_s1, eval_pairs_s2 = train_test_split(\n",
    "    eval_pairs,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Build train and eval dataframes\n",
    "train_df = df.merge(train_pairs, on=[\"country\", \"brand_name\"])\n",
    "eval_df_s1 = df.merge(eval_pairs_s1, on=[\"country\", \"brand_name\"])\n",
    "eval_df_s2 = df.merge(eval_pairs_s2, on=[\"country\", \"brand_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1716264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape, eval_df_s1.shape, eval_df_s2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d080fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df_s1_true = eval_df_s1[eval_df_s1['months_postgx'] >= 0][['country', 'brand_name', 'months_postgx', 'volume']]\n",
    "eval_df_s1.loc[eval_df_s1['months_postgx'] >= 0, 'volume'] = np.nan\n",
    "eval_df_s1.loc[eval_df_s1['months_postgx'] >= 0, 'target_norm'] = np.nan\n",
    "eval_df_s1[\"lag1\"] = np.nan\n",
    "eval_df_s1[\"lag2\"] = np.nan\n",
    "eval_df_s1[\"lag3\"] = np.nan\n",
    "eval_df_s1[\"roll5_mean\"] = np.nan\n",
    "eval_df_s1[\"roll5_std\"]  = np.nan\n",
    "eval_df_s1[\"pred\"] = np.nan\n",
    "\n",
    "eval_df_s2_true = eval_df_s2[eval_df_s2['months_postgx'] >= 6][['country', 'brand_name', 'months_postgx', 'volume']]\n",
    "eval_df_s2.loc[eval_df_s2['months_postgx'] >= 6, 'volume'] = np.nan\n",
    "eval_df_s2.loc[eval_df_s2['months_postgx'] >= 6, 'target_norm'] = np.nan\n",
    "eval_df_s2[\"lag1\"] = np.nan\n",
    "eval_df_s2[\"lag2\"] = np.nan\n",
    "eval_df_s2[\"lag3\"] = np.nan\n",
    "eval_df_s2[\"roll5_mean\"] = np.nan\n",
    "eval_df_s2[\"roll5_std\"]  = np.nan\n",
    "eval_df_s2[\"pred\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94749e06",
   "metadata": {},
   "source": [
    "# Introducing lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3410d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"lag1\"] = train_df.groupby([\"country\", \"brand_name\"])[\"target_norm\"].shift(1)\n",
    "train_df[\"lag2\"] = train_df.groupby([\"country\", \"brand_name\"])[\"target_norm\"].shift(2)\n",
    "train_df[\"lag3\"] = train_df.groupby([\"country\", \"brand_name\"])[\"target_norm\"].shift(3)\n",
    "\n",
    "train_df['roll5_mean'] = train_df.groupby([\"country\", \"brand_name\"])[\"target_norm\"].rolling(5).mean().reset_index()['target_norm']\n",
    "train_df['roll5_std'] = train_df.groupby([\"country\", \"brand_name\"])[\"target_norm\"].rolling(5).std().reset_index()['target_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f684b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b2021",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "    'month', 'months_postgx', 'ther_area', 'main_package',\n",
    "    'biological', 'small_molecule'\n",
    "]\n",
    "\n",
    "num_features = [\n",
    "    'n_gxs', 'hospital_rate',\n",
    "    'Avgj', 'pre_mean', 'pre_std',\n",
    "    'pre_min', 'pre_max', 'pre_trend', 't1_mean', 't1_std', 't1_min',\n",
    "    't1_max', 't1_trend', 't2_mean', 't2_std', 't2_min', 't2_max',\n",
    "    't2_trend', 't3_mean', 't3_std', 't3_min', 't3_max', 't3_trend',\n",
    "    't4_mean', 't4_std', 't4_min', 't4_max', 't4_trend', 't5_mean',\n",
    "    't5_std', 't5_min', 't5_max', 't5_trend', 't6_mean', 't6_std', 't6_min',\n",
    "    't6_max', 't6_trend', 't7_mean', 't7_std', 't7_min', 't7_max',\n",
    "    't7_trend', 't8_mean', 't8_std', 't8_min', 't8_max', 't8_trend',\n",
    "    'months_postgx_sin', 'months_postgx_cos', 'lag1', 'lag2', 'lag3',\n",
    "    'roll5_mean', 'roll5_std'\n",
    "]\n",
    "\n",
    "features = cat_features + num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff646ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool_s1 = Pool(\n",
    "    data=train_df[train_df['months_postgx'] >= 0][features],\n",
    "    label=train_df[train_df['months_postgx'] >= 0]['target_norm'],\n",
    "    cat_features=[features.index(c) for c in cat_features]\n",
    ")\n",
    "\n",
    "model_s1 = CatBoostRegressor(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.03,\n",
    "    depth=8,\n",
    "    loss_function=\"MAE\",\n",
    "    eval_metric=\"MAE\",\n",
    "    random_seed=42,\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "model_s1.fit(train_pool_s1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3d87f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool_s2 = Pool(\n",
    "    data=train_df[train_df['months_postgx'] >= 6][features],\n",
    "    label=train_df[train_df['months_postgx'] >= 6]['target_norm'],\n",
    "    cat_features=[features.index(c) for c in cat_features]\n",
    ")\n",
    "\n",
    "model_s2 = CatBoostRegressor(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.03,\n",
    "    depth=8,\n",
    "    loss_function=\"MAE\",\n",
    "    eval_metric=\"MAE\",\n",
    "    random_seed=42,\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "model_s2.fit(train_pool_s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de55f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "groups = eval_df_s1.groupby([\"country\", \"brand_name\"])\n",
    "\n",
    "for (country, brand), g in groups:\n",
    "\n",
    "    g = g.sort_values(\"months_postgx\").copy()\n",
    "\n",
    "    history = g[g['months_postgx'].isin(range(-5, 0))][\"target_norm\"].tolist()\n",
    "\n",
    "    for idx, row in g.iterrows():\n",
    "        if row['months_postgx'] < 0:\n",
    "            continue\n",
    "\n",
    "        # ----- 1. Insert lag features -----\n",
    "        g.loc[idx, \"lag1\"] = history[-1]\n",
    "        g.loc[idx, \"lag2\"] = history[-2]\n",
    "        g.loc[idx, \"lag3\"] = history[-3]\n",
    "\n",
    "        # ----- 2. Compute rolling features -----\n",
    "        g.loc[idx, \"roll5_mean\"] = np.mean(history[-5:])\n",
    "        g.loc[idx, \"roll5_std\"]  = np.std(history[-5:])\n",
    "\n",
    "        # ----- 3. Prepare row for prediction -----\n",
    "        X_row = g.loc[idx, features]\n",
    "\n",
    "        # Predict\n",
    "        pred = model_s1.predict(X_row.values.reshape(1, -1))[0]\n",
    "\n",
    "        # Save prediction\n",
    "        history.append(pred)\n",
    "        g.loc[idx, \"pred\"] = pred\n",
    "\n",
    "    preds.append(g)\n",
    "\n",
    "# Combine predictions\n",
    "eval_pred_df_s1 = pd.concat(preds)\n",
    "eval_pred_df_s1 = eval_pred_df_s1.sort_index()\n",
    "eval_pred_df_s1 = eval_pred_df_s1[eval_pred_df_s1['months_postgx'] >= 0].drop(['volume'], axis=1)\n",
    "eval_pred_df_s1 = eval_pred_df_s1.merge(eval_df_s1_true, on=[\"country\", \"brand_name\", \"months_postgx\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8330cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "groups = eval_df_s2.groupby([\"country\", \"brand_name\"])\n",
    "\n",
    "for (country, brand), g in groups:\n",
    "\n",
    "    g = g.sort_values(\"months_postgx\").copy()\n",
    "\n",
    "    history = g[g['months_postgx'].isin(range(1, 6))][\"target_norm\"].tolist()\n",
    "\n",
    "    for idx, row in g.iterrows():\n",
    "        if row['months_postgx'] < 6:\n",
    "            continue\n",
    "\n",
    "        # ----- 1. Insert lag features -----\n",
    "        g.loc[idx, \"lag1\"] = history[-1]\n",
    "        g.loc[idx, \"lag2\"] = history[-2]\n",
    "        g.loc[idx, \"lag3\"] = history[-3]\n",
    "\n",
    "        # ----- 2. Compute rolling features -----\n",
    "        g.loc[idx, \"roll5_mean\"] = np.mean(history[-5:])\n",
    "        g.loc[idx, \"roll5_std\"]  = np.std(history[-5:])\n",
    "\n",
    "        # ----- 3. Prepare row for prediction -----\n",
    "        X_row = g.loc[idx, features]\n",
    "\n",
    "        # Predict\n",
    "        pred = model_s2.predict(X_row.values.reshape(1, -1))[0]\n",
    "\n",
    "        # Save prediction\n",
    "        history.append(pred)\n",
    "        g.loc[idx, \"pred\"] = pred\n",
    "\n",
    "    preds.append(g)\n",
    "\n",
    "# Combine predictions\n",
    "eval_pred_df_s2 = pd.concat(preds)\n",
    "eval_pred_df_s2 = eval_pred_df_s2.sort_index()\n",
    "eval_pred_df_s2 = eval_pred_df_s2[eval_pred_df_s2['months_postgx'] >= 6].drop(['volume'], axis=1)\n",
    "eval_pred_df_s2 = eval_pred_df_s2.merge(eval_df_s2_true, on=[\"country\", \"brand_name\", \"months_postgx\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9b3cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_s1(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    df must contain columns:\n",
    "    - target_norm\n",
    "    - pred\n",
    "    - months_postgx\n",
    "    - Avgj\n",
    "    - country_brand_id  (integer id for grouping)\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for _, g in df.groupby([\"country\", \"brand_name\"]):\n",
    "        avg = g[\"Avgj\"].iloc[0]\n",
    "        y_true = g[\"volume\"].values\n",
    "        y_pred = g[\"pred\"].values * avg\n",
    "        m = g[\"months_postgx\"].values\n",
    "\n",
    "        # Monthly error (0-23)\n",
    "        mask_0_23 = (m >= 0) & (m <= 23)\n",
    "        monthly_err = np.abs(y_true[mask_0_23] - y_pred[mask_0_23]).sum() / (24 * avg)\n",
    "\n",
    "        # Accumulated error 0–5\n",
    "        mask_0_5 = (m >= 0) & (m <= 5)\n",
    "        acc_0_5 = np.abs(y_true[mask_0_5].sum() - y_pred[mask_0_5].sum()) / (6 * avg)\n",
    "\n",
    "        # Accumulated error 6–11\n",
    "        mask_6_11 = (m >= 6) & (m <= 11)\n",
    "        acc_6_11 = np.abs(y_true[mask_6_11].sum() - y_pred[mask_6_11].sum()) / (6 * avg)\n",
    "\n",
    "        # Accumulated error 12–23\n",
    "        mask_12_23 = (m >= 12) & (m <= 23)\n",
    "        acc_12_23 = np.abs(y_true[mask_12_23].sum() - y_pred[mask_12_23].sum()) / (12 * avg)\n",
    "\n",
    "        # Weighted sum\n",
    "        pe = (\n",
    "            0.2 * monthly_err +\n",
    "            0.5 * acc_0_5 +\n",
    "            0.2 * acc_6_11 +\n",
    "            0.1 * acc_12_23\n",
    "        )\n",
    "\n",
    "        results.append(pe)\n",
    "\n",
    "    return np.mean(results)\n",
    "\n",
    "\n",
    "def metric_s2(df: pd.DataFrame):\n",
    "    results = []\n",
    "\n",
    "    for _, g in df.groupby([\"country\", \"brand_name\"]):\n",
    "        avg = g[\"Avgj\"].iloc[0]\n",
    "        y_true = g[\"volume\"].values\n",
    "        y_pred = g[\"pred\"].values * avg\n",
    "        m = g[\"months_postgx\"].values\n",
    "\n",
    "        # Monthly error (6-23)\n",
    "        mask_6_23 = (m >= 6) & (m <= 23)\n",
    "        monthly_err = np.abs(y_true[mask_6_23] - y_pred[mask_6_23]).sum() / (18 * avg)\n",
    "\n",
    "        # Accumulated error 6–11\n",
    "        mask_6_11 = (m >= 6) & (m <= 11)\n",
    "        acc_6_11 = np.abs(y_true[mask_6_11].sum() - y_pred[mask_6_11].sum()) / (6 * avg)\n",
    "\n",
    "        # Accumulated error 12–23\n",
    "        mask_12_23 = (m >= 12) & (m <= 23)\n",
    "        acc_12_23 = np.abs(y_true[mask_12_23].sum() - y_pred[mask_12_23].sum()) / (12 * avg)\n",
    "\n",
    "        pe = (\n",
    "            0.2 * monthly_err +\n",
    "            0.5 * acc_6_11 +\n",
    "            0.3 * acc_12_23\n",
    "        )\n",
    "\n",
    "        results.append(pe)\n",
    "\n",
    "    return np.mean(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb149ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scenario 1 metric:\", metric_s1(eval_pred_df_s1))\n",
    "print(\"Scenario 2 metric:\", metric_s2(eval_pred_df_s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f66c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_vol = pd.read_csv('data/test/df_volume_test.csv')\n",
    "t_gxs = pd.read_csv('data/test/df_generics_test.csv')\n",
    "t_info = pd.read_csv('data/test/df_medicine_info_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9d329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_vol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82cc92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend t_vol to include months_postgx (0 -> 23) with volumn NaN and month continued from last row grouped by \"country\", \"brand_name\"\n",
    "month_to_int = {\n",
    "    \"Jan\": 1, \"Feb\": 2, \"Mar\": 3, \"Apr\": 4,\n",
    "    \"May\": 5, \"Jun\": 6, \"Jul\": 7, \"Aug\": 8,\n",
    "    \"Sep\": 9, \"Oct\": 10, \"Nov\": 11, \"Dec\": 12\n",
    "}\n",
    "\n",
    "int_to_month = {v: k for k, v in month_to_int.items()}\n",
    "\n",
    "extended_rows = []\n",
    "\n",
    "for (country, brand), g in t_vol.groupby([\"country\", \"brand_name\"]):\n",
    "\n",
    "    g = g.sort_values(\"months_postgx\")\n",
    "\n",
    "    # last pre-gx row (months_postgx = -1)\n",
    "    last_row = g.iloc[-1]\n",
    "    last_moth_postgx = last_row[\"months_postgx\"]\n",
    "    last_month_str = last_row[\"month\"]\n",
    "    last_month_int = month_to_int[last_month_str]\n",
    "\n",
    "    # create new rows for horizon months_postgx = 0..23\n",
    "    for i, h in enumerate(list(range(last_moth_postgx + 1, 24))):\n",
    "\n",
    "        # wrap month: 1..12\n",
    "        new_month_int = ((last_month_int + i) % 12) + 1\n",
    "        new_month_str = int_to_month[new_month_int]\n",
    "\n",
    "        extended_rows.append({\n",
    "            \"country\": country,\n",
    "            \"brand_name\": brand,\n",
    "            \"month\": new_month_str,\n",
    "            \"months_postgx\": h,\n",
    "            \"volume\": np.nan\n",
    "        })\n",
    "\n",
    "# Build future DF\n",
    "df_future = pd.DataFrame(extended_rows)\n",
    "\n",
    "# Combine original + extended rows\n",
    "t_vol = pd.concat([t_vol, df_future], ignore_index=True)\n",
    "\n",
    "t_vol = t_vol.sort_values(\n",
    "    [\"country\", \"brand_name\", \"months_postgx\"]\n",
    ").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bb4223",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df = t_vol.merge(\n",
    "    t_gxs,\n",
    "    on=['country', 'brand_name', 'months_postgx'],\n",
    "    how='left',\n",
    "    validate='one_to_one'\n",
    ")\n",
    "t_df = t_df.merge(\n",
    "    t_info,\n",
    "    on=['country', 'brand_name'],\n",
    "    how='left',\n",
    "    validate='many_to_one'\n",
    ")\n",
    "# Compute Avgj\n",
    "avgj = (\n",
    "    t_df[t_df[\"months_postgx\"].between(-12, -1)]\n",
    "    .groupby([\"country\", \"brand_name\"])[\"volume\"]\n",
    "    .mean()\n",
    "    .rename(\"Avgj\")\n",
    ")\n",
    "\n",
    "t_df = t_df.merge(avgj, on=[\"country\", \"brand_name\"], how=\"left\", validate=\"many_to_one\")\n",
    "t_df[\"target_norm\"] = t_df[\"volume\"] / t_df[\"Avgj\"]\n",
    "pre = t_df[t_df[\"months_postgx\"] < 0]\n",
    "\n",
    "pre_stats = pre.groupby([\"country\", \"brand_name\"])[\"target_norm\"].agg(\n",
    "    pre_mean=\"mean\",\n",
    "    pre_std=\"std\",\n",
    "    pre_min=\"min\",\n",
    "    pre_max=\"max\",\n",
    "    pre_trend=lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x)>1 else 0\n",
    ")\n",
    "\n",
    "t_df = t_df.merge(pre_stats, on=[\"country\", \"brand_name\"], how=\"left\", validate=\"many_to_one\")\n",
    "windows = {\n",
    "    \"t1\": (-24, -22),\n",
    "    \"t2\": (-21, -19),\n",
    "    \"t3\": (-18, -16),\n",
    "    \"t4\": (-15, -13),\n",
    "    \"t5\": (-12, -10),\n",
    "    \"t6\": (-9, -7),\n",
    "    \"t7\": (-6, -4),\n",
    "    \"t8\": (-3, -1),\n",
    "}\n",
    "\n",
    "trimester_frames = []\n",
    "\n",
    "for name, (start, end) in windows.items():\n",
    "    tmp = (\n",
    "        t_df[t_df[\"months_postgx\"].between(start, end)]\n",
    "        .groupby([\"country\", \"brand_name\"])[\"target_norm\"]\n",
    "        .agg(\n",
    "            **{\n",
    "                f\"{name}_mean\": \"mean\",\n",
    "                f\"{name}_std\": \"std\",\n",
    "                f\"{name}_min\": \"min\",\n",
    "                f\"{name}_max\": \"max\",\n",
    "                f\"{name}_trend\": lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x)>1 else 0,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    trimester_frames.append(tmp)\n",
    "\n",
    "# Combine trimester stats\n",
    "trimester_stats = pd.concat(trimester_frames, axis=1)\n",
    "\n",
    "# Merge\n",
    "t_df = t_df.merge(trimester_stats, on=[\"country\", \"brand_name\"], how=\"left\")\n",
    "t_df['months_postgx_sin'] = np.sin(t_df['months_postgx']* (2.*np.pi/12))\n",
    "t_df['months_postgx_cos'] = np.cos(t_df['months_postgx']* (2.*np.pi/12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec66c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_real = (\n",
    "    t_df[t_df[\"volume\"].notna()]\n",
    "    .groupby([\"country\", \"brand_name\"])[\"months_postgx\"]\n",
    "    .max()\n",
    "    .rename(\"max_real_month\")\n",
    ")\n",
    "t_df_with_max = t_df.merge(max_real, on=[\"country\", \"brand_name\"])\n",
    "t_df_s1 = t_df_with_max[t_df_with_max[\"max_real_month\"] == -1].copy().drop(\"max_real_month\", axis=1)\n",
    "t_df_s2 = t_df_with_max[t_df_with_max[\"max_real_month\"] == 5].copy().drop(\"max_real_month\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100b7144",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "groups = t_df_s1.groupby([\"country\", \"brand_name\"])\n",
    "\n",
    "for (country, brand), g in groups:\n",
    "\n",
    "    g = g.sort_values(\"months_postgx\").copy()\n",
    "\n",
    "    history = g[g['months_postgx'].isin(range(-5, 0))][\"target_norm\"].tolist()\n",
    "\n",
    "    for idx, row in g.iterrows():\n",
    "        if row['months_postgx'] < 0:\n",
    "            continue\n",
    "\n",
    "        # ----- 1. Insert lag features -----\n",
    "        g.loc[idx, \"lag1\"] = history[-1]\n",
    "        g.loc[idx, \"lag2\"] = history[-2]\n",
    "        g.loc[idx, \"lag3\"] = history[-3]\n",
    "\n",
    "        # ----- 2. Compute rolling features -----\n",
    "        g.loc[idx, \"roll5_mean\"] = np.mean(history[-5:])\n",
    "        g.loc[idx, \"roll5_std\"]  = np.std(history[-5:])\n",
    "\n",
    "        # ----- 3. Prepare row for prediction -----\n",
    "        X_row = g.loc[idx, features]\n",
    "\n",
    "        # Predict\n",
    "        pred = model_s1.predict(X_row.values.reshape(1, -1))[0]\n",
    "\n",
    "        # Save prediction\n",
    "        history.append(pred)\n",
    "        g.loc[idx, \"volume\"] = pred\n",
    "\n",
    "    preds.append(g)\n",
    "\n",
    "# Combine predictions\n",
    "t_pred_df_s1 = pd.concat(preds)\n",
    "t_pred_df_s1 = t_pred_df_s1.sort_index()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
